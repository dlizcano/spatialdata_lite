[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introducción al procesamiento, visualización y análisis de datos espaciales en R",
    "section": "",
    "text": "Este es un curso de un día para el V Congreso Colombiano de mastozoología.\n\n\n\nIntroducción al análisis de datos en R. Tipos de objetos en R. Visualización para comprobar errores y patrones en los datos (ggplot) Preparación de tablas para la generación de análisis espaciales (dplyr – tidyr)\n\n\n\nImportación y visualización de datos espaciales (ps, sf, raster, rgdal). Generación de mapas (raster, ggmap, leaflet)\n\n\n\nLos datos requridos para completar el curso pueden ser descargados de internet\n\n\n\nComputador con acceso a internet. Contar con R y RStudio previamente instalados. La instalación del programa no se explicará durante el curso.\nAntes del curso instalar los paquetes:\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"rgbif\")\ninstall.packages(\"sf\")\ninstall.packages(\"terra\")\ninstall.packages(\"mapview\")\ninstall.packages(\"maps\")\ninstall.packages(\"elevatr\")\n\nLa experiencia requerida en R es mínima, sin embargo, se espera que los participantes estén familiarizados con el siguiente tipo de objetos básicos R: vectores, listas y dataframes. Puedes ver aprender o repasar el manejo básico de R en éste tutorial\nTambien se requiere, un conocimiento básico sobre conceptos relacionados con sistemas de coordenadas y proyecciones geográficas, aunque no es esencial."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Diego J. Lizcano, Ph.D. Sociedad Colombiana de Mastozoología (SCMas)\nAndres Felipe Suárez-Castro, Ph.D. Griffith University: Brisbane, Australia."
  },
  {
    "objectID": "about.html#créditos",
    "href": "about.html#créditos",
    "title": "About",
    "section": "Créditos",
    "text": "Créditos\nEste mini curso es una version ligera del fantastico curso Introducción al procesamiento, visualización y mapeo de datos espaciales en R preparado por el Dr. Felipe Suárez-Castro.\nAlgunos ejercicios presentados en este curso fueron adaptados del curso desarrollado por C.J. Brown, D. Schoeman, A.J. Richardson y B. Venables, el cual se encuentra disponible en:\nhttps://www.seascapemodels.org/code.html"
  },
  {
    "objectID": "AM.html",
    "href": "AM.html",
    "title": "AM",
    "section": "",
    "text": "En primer lugar, es importante recordar que la organización es clave cuando se está generando un nuevo código. En este sentido, le recomendamos que cree una carpeta cerca de c: para cada nuevo proyecto. Puede hacer esto como un proyecto de Rstudio, para esto (dirijase a: Archivo> Nuevo proyecto) o simplemente como una nueva carpeta. Dentro de esta carpeta, cree una carpeta de datos donde guardará sus datos sin procesar. Puede almacenar algunos objetos intermedios en otra subcarpeta. También cree una carpeta para su código R y una carpeta para guardar sus figuras.\nla organización de carpetas que se sugere es:\nC://curso\n- data\n- R\n- fig\n\n\n\nDurante el curso utilizaremos datos que vamos a descargar de la plataforma GBIF con el paquete rgbif. El ejercicio lo haremos con una especie de Mamífero amenazado, la danta de montaña (Tapirus pinchaque).\n\n\n\nDanta de montaña\n\n\n\nTenga en cuenta que se requiere conexión a internet y que podemos estar descargando muchos datos desde GBIF, así que este paso puede tardar unos segundos…\n\n\n\nCode\n#######################################\n## DOWNLOAD AND CLEAN DATA FROM GBIF ##\n#######################################\nlibrary(rgbif)\n# IF YOU HAVE ONLY ONE SPECIES ----\nspecies1 <- c(\"Tapirus pinchaque\")\n# download GBIF occurrence data for this species; this takes time if there are many data points!\ngbif_data_sp1 <- occ_data(scientificName = species1, hasCoordinate = TRUE, limit = 20000)\n# create a table with the downloaded data:\ndat_sp1 <- gbif_data_sp1$data\n# if \"Records found\" is larger than \"Records returned\", you need to increase the 'limit' argument above -- see help(occ_data) for options and limitations\n# if your species is widespread but you want to work on a particular region, you can download records within a specified window of coordinates:\n\n\n# colombia_data <- occ_data(scientificName = species1, hasCoordinate = TRUE, limit = 20000, decimalLatitude = \"0.996444, 5\")#decimalLongitude = \"-10, 10\", decimalLatitude = \"35, 55\")  # note that coordinate ranges must be specified this way: \"smaller, larger\" (e.g. \"-5, -2\")\n# gbif_data\n\n\nRevise el entorno global Global Environment, en donde ahora deben aparecer tres objetos en la memoria. Uno llamado myspecies que corresponde a la especie. Otro llamado “gbif_data” con los datos descargados del GBIF y el objeto “dat” que es una tabla que contiene los registros de la especie de interes.\n\n\n\nUna vez que la tabla esté cargada en el entorno global, es necesario hacer algunas verificaciones iniciales de los datos. Hay algunas funciones clave en R que nos permiten ver los datos de diferentes maneras. Es deseable que estas funciones se conviertan en una rutina estándar en sus scripts, pues le ayudarán a determinar si sus datos están formateados correctamente.\nPrimero, verificaremos el tipo de datos de cada una de las variables en nuestra tabla de datos. Tome un tiempo para entender cada una de estas variables.\n\n\nCode\n# ejecute una sola linea a la vez\nhead(dat_sp1)\ntail(dat_sp1)\n# ver los datos de la tabla\nView(dat_sp1)\nnames(dat_sp1)\nnrow(dat_sp1)\nncol(dat_sp1)\nlength(unique(dat_sp1$stateProvince))\nunique(dat_sp1$stateProvince)\nlength(unique(dat_sp1$year))\nunique(dat_sp1$year)\ntable(dat_sp1$publishingCountry)\nsummary(dat)\n\n\n\n\n\nOrdenar los datos significa manipularlos con el fin de facilitar su exploración y análisis. El paquete \"dplyr\", incluido en tidyverse, proporciona una serie de funciones útiles en este sentido. El marco conceptual que sustenta dplyr se llama “Gramática de la manipulación de datos”. A continuación revisaremos diferentes funciones para filtrar, resumir y combinar diferentes tablas.\n\n\nCode\n# cargar el paquete dplyr\nlibrary(dplyr)\n\n\n\n\n\nEmpecemos por explorar los datos para una region. Para ello, podemos utilizar la función filter, filtrando los datos de Risaralda, Quindío, Caldas y Tolima.\n\n\nCode\ndat_nevados <- dplyr::filter(dat_sp1, stateProvince == c(\"Risaralda\", \"Quindío\", \"Caldas\", \"Tolima\")) \n\nhead(dat_nevados)\n\n\nTambién es posible que deseemos seleccionar algunas columnas de nuestro conjunto de datos. Podemos hacer esto fácilmente con las herramientas de indexación de dataframes de R. En nuestro caso selecionaremos las columnas que son de nuestro interes.\n\n\nCode\n# get the columns that matter for mapping and cleaning the occurrence data:\nsp1_coords <- gbif_data_sp1$data[ , c(\"scientificName\", \"decimalLongitude\", \"decimalLatitude\", \"individualCount\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\", \"institutionCode\", \"references\")]\n\nhead(sp1_coords) \n\n\n\n\n\nNuestra tabla de registros tiene información específica sobre las localidades de una sola especie. Con el fin de entender como combinar tablas descargaremos los datos de otra especie. En este caso el Oso Andino (Tremarctos ornatus).\n\n\n\nOso andino\n\n\n\nTenga en cuenta que se requiere conexión a internet y que podemos estar descargando muchos datos desde GBIF, así que este paso puede tardar unos segundos…\n\nEl paquete dplyr proporciona un conjunto útil de funciones para unir tablas que tienen columnas en común. Escriba ?full_join en su consola y obtendrá una lista de todos los tipos de unión que admite dplyr.\nHoy usaremos full_join para unir los registros de dos especies en una sola tabla. La funcion full_join permite mantener las filas que no coinciden también). Otras funcionalidades de join se ven en la version ampliada de este curso.\n\n\nCode\ndat_oso_danta  <- full_join(x = dat_sp2, y = dat_sp1)\n\n\n\n\n\nA menudo, es más fácil explorar datos mediante el uso de gráficos. R tiene buenos paquetes base para realizar gráficos. Hoy usaremos el paquete ggplot2.\n\n\nCode\nlibrary(ggplot2)\n\n\nPrimero, podemos generar un histograma para revisar la distribución de los registos por año. Por ahora no nos preocuparemos demasiado por la estética de la gráfica.\n\n\nCode\nggplot(dat_oso_danta) + \n  aes(x = year) + \n  geom_histogram()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nEl componente ggplot(dat_input) determina la tabla de datos de la cual obtendremos las variables. Esta función también crea la página para el gráfico. El componente aes() hace referencia a la estética del gráfico, y aquí lo usamos para declarar que el eje x que corresponde a el año. Luego geom_histogram() declara el tipo de gráfico que se utilizará. En este caso se refiere al histograma.\nInténtelo de nuevo, pero esta vez añada un color para cada especie.\n\n\nCode\nggplot(dat_oso_danta) + \n  aes(x = year, fill = scientificName) +\n  geom_histogram()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nVamos a graficar de nuevo los puntos de acuerdo a la especie. Para ello, incluya el argumento “color = scientificName” dentro de aes(). Observe que podemos ver que hay unos puntos que se comportan como outliers y debemos eliminarlos.\n\n\nCode\nggplot(dat_oso_danta) + \n  aes(x = decimalLongitude, y = decimalLatitude, color = scientificName) +\n  geom_point()\n\n\n\n\n\nVamos a filtrar las dos especies de interes\n\n\nCode\ndat_oso_danta_filtrado <- dat_oso_danta %>% \n  filter(scientificName == c(\"Tremarctos ornatus (F.G.Cuvier, 1825)\", \"Tapirus pinchaque (Roulin, 1829)\")) %>%\n  filter(decimalLatitude <= 20 & decimalLatitude >= -20)\n\n\nVeamos como queda\n\n\nCode\nggplot(dat_oso_danta_filtrado) + \n  aes(x = decimalLongitude, y = decimalLatitude, color = scientificName) +\n  geom_point()\n\n\n\n\n\n\n\n\nPresentar los datos en forma de gráficos es importante, pero ver los números concretos también puede ser útil. Supongamos que queremos identificar la elevación promedio y la desviación estandar a la que han sido recolectados los registros, así como el número de registros por departamento.\nPara hacer esto, vamos a agrupar los datos con la función group_by seguida de summarize para obtener las estadísticas en cada departamento.\n\n\nCode\ndatg <- group_by(dat_oso_danta_filtrado, stateProvince)\n\n\ngroup_by() toma una tabla existente y la convierte en una tabla agrupada donde las operaciones se realizan “por grupo”. Revise el objeto datg y verá que los datos en sí mismos no han cambiado. Sin embargo, los datos están agrupados en 31 departamentos.\nAhora podemos utilizar esa tabla para resumir los datos con algunas estadísticas deseadas\n\n\nCode\ndat_elev_sum <- \n    summarize(datg,\n              mean_elev = mean(elevation, na.rm=T),\n              sd_elev = sd(elevation, na.rm=T),\n              n = n())\ndat_elev_sum\n\n\n# A tibble: 62 × 4\n   stateProvince mean_elev sd_elev     n\n   <chr>             <dbl>   <dbl> <int>\n 1 Amazonas           NaN      NA     48\n 2 Ancash             NaN      NA      9\n 3 Antioquia         1797.    627.    16\n 4 Apurimac           NaN      NA      7\n 5 Ayacucho           NaN      NA      3\n 6 Azuay              NaN      NA      2\n 7 Bolívar           1106.     NA      1\n 8 Boyacá            2208.   1087.    37\n 9 Cajamarca          NaN      NA     56\n10 Caldas            3430.    414.     2\n# ℹ 52 more rows\n\n\nPara ejecutar varios pasos como los anteriores, podemos usar la función %>%, la cual permite utilizar el resultado de una función como el primer argumento del siguiente. Por ejemplo, estas líneas de código hacen lo mismo:\n\n\nCode\ngroup_by(dat_oso_danta_filtrado, stateProvince)\n#es lo mismo que\ndat_oso_danta_filtrado %>% group_by(., stateProvince)\n\n\nLas función %>% es útil para encadenar operaciones de varios pasos en tablas. Para la mayoría de las funciones compatibles con %>%, el. ni siquiera es necesario, lo que hace que nuestro código sea aún más fácil de leer.\nAquí calculamos la desviación estándar y media de la elevación para cada departamento, así como el número de filas (registros) n () para cada departamento:\n\n\nCode\ndat_elev_sum <- \n  dat_oso_danta_filtrado %>% \n  group_by(scientificName) %>%\n  summarize(mean_elev  = mean(elevation, na.rm=T),\n            sd_elev = sd(elevation, na.rm=T),\n            n = n())\n\n\nAhora vamos a graficar la media y la desviación estándar de la elevación por especie\n\n\nCode\ndat_oso_danta_filtrado %>% \n  group_by(scientificName) %>%\n  summarize(mean_elev  = mean(elevation, na.rm=T),\n            sd_elev = sd(elevation, na.rm=T),\n            n = n()) %>%\n  ungroup() %>%\n  ggplot(aes(x = scientificName, y = mean_elev)) +\n  geom_linerange(aes(ymin = mean_elev - sd_elev, ymax = mean_elev + sd_elev)) +\n  geom_point()\n\n\n\n\n\n\n\n\nSupongamos que ahora queremos visualizar la distribución de registros a través del tiempo. Además, queremos ver la incidencia de diferentes técnicas de muestreo en el registro de especies. En primer lugar, necesitamos contar los registros por año.\n\n\nUtilice las funciones group_by, summarize y filter para contar los registros de cada especie por año desde 1950 por cada técnica de muestreo (basisOfRecord)\n\n\nCode\ndat_per_year<-dat_oso_danta_filtrado %>% \n                group_by(year,basisOfRecord) %>%\n                summarize(n = n()) %>%\n                filter(year > 1949)\n\n\nAhora podemos graficar los datos agrupando por técnica de muestro\n\n\nCode\np1<-ggplot(dat_per_year, aes(x=year, y=n,color = basisOfRecord)) +\n    geom_line(size = 1) \np1\n\n\n\n\n\nAñadir una línea en que muestre el año con más registros\n\n\nCode\np2<-p1 +\n  geom_vline(xintercept = 2016,colour=\"black\", linetype = \"longdash\") \np2\n\n\n\n\n\nLa función anotate() nos permite añadir texto en ubicaciones específicas de nuestro gráfico\n\n\nCode\np3<-p2 +\n  annotate(\"text\", label = \"2016\", x = 2017, y = 1300, size = 4, colour = \"black\")\np3\n\n\n\n\n\nFinalmente, podemos cambiar el tamaño del texto de los ejes\n\n\nCode\ne1<-p3 +\n  theme_bw()+\n  theme(legend.position = \"right\",\n        legend.title = element_blank(),\n        legend.text = element_text(size = 14),\n        text = element_text(size = 14),\n        axis.text.x = element_text(size = 12),\n        axis.text.y = element_text(size = 12))+\n    ylab(\"# registros\")+ xlab(\"año\")+\n  ggtitle(\"Número de registros de danta y oso\")\ne1\n\n\n\n\n\n\n\n\n\nTenga en cuenta que es una buena practica citar correctamente los datos que se descargan de GBIF.\n\n\nCode\n# get the DOIs for citing these data properly:\n\ngbif_citation(gbif_data_sp1) # para la danta\n\ngbif_citation(gbif_data_sp2) # para la el oso\n\n# note: if you need or prefer only one DOI for the entire dataset, download the dataset directly from www.gbif.org and then import the .csv to R. It is very important to properly cite the data sources! GBIF is not a source, just a repository for many people who put in very hard work to collect these data and make them available.\n\n\n¡Hemos llegado al final de la mañana! Los conceptos aprendidos el día de hoy serán fundamentales para sacar el mayor provecho en la tarde. Es hora de Almorzar :)"
  },
  {
    "objectID": "AM.html#caso-de-estudio",
    "href": "AM.html#caso-de-estudio",
    "title": "AM",
    "section": "Caso de estudio",
    "text": "Caso de estudio\nDurante el curso utilizaremos datos que vamos a descargar de la plataforma GBIF con el paquete rgbif. El ejercicio lo haremos con una especie de Mamífero amenazado, la danta de montaña (Tapirus pinchaque).\n\n\n\nDanta\n\n\n\n#######################################\n## DOWNLOAD AND CLEAN DATA FROM GBIF ##\n#######################################\nlibrary(rgbif)\n# IF YOU HAVE ONLY ONE SPECIES ----\nspecies1 <- c(\"Tapirus pinchaque\")\n# download GBIF occurrence data for this species; this takes time if there are many data points!\ngbif_data_sp1 <- occ_data(scientificName = species1, hasCoordinate = TRUE, limit = 20000)\n# create a table with the downloaded data:\ndat_sp1 <- gbif_data_sp1$data\n# if \"Records found\" is larger than \"Records returned\", you need to increase the 'limit' argument above -- see help(occ_data) for options and limitations\n# if your species is widespread but you want to work on a particular region, you can download records within a specified window of coordinates:\n\n\n# colombia_data <- occ_data(scientificName = species1, hasCoordinate = TRUE, limit = 20000, decimalLatitude = \"0.996444, 5\")#decimalLongitude = \"-10, 10\", decimalLatitude = \"35, 55\")  # note that coordinate ranges must be specified this way: \"smaller, larger\" (e.g. \"-5, -2\")\n# gbif_data\n\n# get the DOIs for citing these data properly:\n# gbif_citation(gbif_data)\n# note: if you need or prefer only one DOI for the entire dataset, download the dataset directly from www.gbif.org and then import the .csv to R. It is very important to properly cite the data sources! GBIF is not a source, just a repository for many people who put in very hard work to collect these data and make them available\n\n\n# dat_sp1\n\nRevise el entorno global Global Environment, en donde ahora deben aparecer tres objetos en la memoria. Uno llamado myspecies que corresponde a la especie. Otro llamado “gbif_data” con los datos descargados del GBIF y el objeto “dat” que es una tabla que contiene los registros de la especie de interes."
  },
  {
    "objectID": "AM.html#revisión-inicial-de-los-datos",
    "href": "AM.html#revisión-inicial-de-los-datos",
    "title": "AM",
    "section": "Revisión inicial de los datos",
    "text": "Revisión inicial de los datos\nUna vez que la tabla esté cargada en el entorno global, es necesario hacer algunas verificaciones iniciales de los datos. Hay algunas funciones clave en R que nos permiten ver los datos de diferentes maneras. Es deseable que estas funciones se conviertan en una rutina estándar en sus scripts, pues le ayudarán a determinar si sus datos están formateados correctamente.\nPrimero, verificaremos el tipo de datos de cada una de las variables en nuestra tabla de datos. Tome un tiempo para entender cada una de estas variables.\n\nhead(dat_sp1)\n\n# A tibble: 6 × 146\n  key        scientificName   decimalLatitude decimalLongitude issues datasetKey\n  <chr>      <chr>                      <dbl>            <dbl> <chr>  <chr>     \n1 4510385651 Tapirus pinchaq…          -0.525            -77.9 cdc,c… 50c9509d-…\n2 4510247483 Tapirus pinchaq…           4.77             -75.6 cdc,c… 50c9509d-…\n3 4510210445 Tapirus pinchaq…          -0.418            -77.9 cdc,c… 50c9509d-…\n4 4510458382 Tapirus pinchaq…          -0.457            -77.9 cdc,c… 50c9509d-…\n5 4510437523 Tapirus pinchaq…          -0.520            -77.9 cdc,c… 50c9509d-…\n6 4510466495 Tapirus pinchaq…          -0.424            -77.9 cdc,c… 50c9509d-…\n# ℹ 140 more variables: publishingOrgKey <chr>, installationKey <chr>,\n#   hostingOrganizationKey <chr>, publishingCountry <chr>, protocol <chr>,\n#   lastCrawled <chr>, lastParsed <chr>, crawlId <int>, basisOfRecord <chr>,\n#   occurrenceStatus <chr>, taxonKey <int>, kingdomKey <int>, phylumKey <int>,\n#   classKey <int>, orderKey <int>, familyKey <int>, genusKey <int>,\n#   speciesKey <int>, acceptedTaxonKey <int>, acceptedScientificName <chr>,\n#   kingdom <chr>, phylum <chr>, order <chr>, family <chr>, genus <chr>, …\n\ntail(dat_sp1)\n\n# A tibble: 6 × 146\n  key        scientificName   decimalLatitude decimalLongitude issues datasetKey\n  <chr>      <chr>                      <dbl>            <dbl> <chr>  <chr>     \n1 3051955835 Tapirus pinchaq…           -4.39            -79.1 rdativ cb16fc5b-…\n2 3051891362 Tapirus pinchaq…           -4.39            -79.1 rdativ cb16fc5b-…\n3 3051891347 Tapirus pinchaq…           -4.39            -79.1 rdativ cb16fc5b-…\n4 3051891351 Tapirus pinchaq…           -4.39            -79.1 rdativ cb16fc5b-…\n5 3051891352 Tapirus pinchaq…           -4.39            -79.1 rdativ cb16fc5b-…\n6 3051891374 Tapirus pinchaq…           -4.39            -79.1 rdativ cb16fc5b-…\n# ℹ 140 more variables: publishingOrgKey <chr>, installationKey <chr>,\n#   hostingOrganizationKey <chr>, publishingCountry <chr>, protocol <chr>,\n#   lastCrawled <chr>, lastParsed <chr>, crawlId <int>, basisOfRecord <chr>,\n#   occurrenceStatus <chr>, taxonKey <int>, kingdomKey <int>, phylumKey <int>,\n#   classKey <int>, orderKey <int>, familyKey <int>, genusKey <int>,\n#   speciesKey <int>, acceptedTaxonKey <int>, acceptedScientificName <chr>,\n#   kingdom <chr>, phylum <chr>, order <chr>, family <chr>, genus <chr>, …\n\n#ver los datos de la tabla\nView(dat_sp1)\nnames(dat_sp1)\n\n  [1] \"key\"                            \"scientificName\"                \n  [3] \"decimalLatitude\"                \"decimalLongitude\"              \n  [5] \"issues\"                         \"datasetKey\"                    \n  [7] \"publishingOrgKey\"               \"installationKey\"               \n  [9] \"hostingOrganizationKey\"         \"publishingCountry\"             \n [11] \"protocol\"                       \"lastCrawled\"                   \n [13] \"lastParsed\"                     \"crawlId\"                       \n [15] \"basisOfRecord\"                  \"occurrenceStatus\"              \n [17] \"taxonKey\"                       \"kingdomKey\"                    \n [19] \"phylumKey\"                      \"classKey\"                      \n [21] \"orderKey\"                       \"familyKey\"                     \n [23] \"genusKey\"                       \"speciesKey\"                    \n [25] \"acceptedTaxonKey\"               \"acceptedScientificName\"        \n [27] \"kingdom\"                        \"phylum\"                        \n [29] \"order\"                          \"family\"                        \n [31] \"genus\"                          \"species\"                       \n [33] \"genericName\"                    \"specificEpithet\"               \n [35] \"taxonRank\"                      \"taxonomicStatus\"               \n [37] \"iucnRedListCategory\"            \"dateIdentified\"                \n [39] \"coordinateUncertaintyInMeters\"  \"continent\"                     \n [41] \"stateProvince\"                  \"year\"                          \n [43] \"month\"                          \"day\"                           \n [45] \"eventDate\"                      \"startDayOfYear\"                \n [47] \"endDayOfYear\"                   \"modified\"                      \n [49] \"lastInterpreted\"                \"references\"                    \n [51] \"license\"                        \"isSequenced\"                   \n [53] \"isInCluster\"                    \"datasetName\"                   \n [55] \"recordedBy\"                     \"identifiedBy\"                  \n [57] \"geodeticDatum\"                  \"class\"                         \n [59] \"countryCode\"                    \"gbifRegion\"                    \n [61] \"country\"                        \"publishedByGbifRegion\"         \n [63] \"rightsHolder\"                   \"identifier\"                    \n [65] \"http://unknown.org/nick\"        \"informationWithheld\"           \n [67] \"verbatimEventDate\"              \"gbifID\"                        \n [69] \"verbatimLocality\"               \"collectionCode\"                \n [71] \"occurrenceID\"                   \"taxonID\"                       \n [73] \"catalogNumber\"                  \"institutionCode\"               \n [75] \"eventTime\"                      \"http://unknown.org/captive\"    \n [77] \"identificationID\"               \"datasetID\"                     \n [79] \"vernacularName\"                 \"institutionID\"                 \n [81] \"occurrenceRemarks\"              \"language\"                      \n [83] \"type\"                           \"individualCount\"               \n [85] \"elevation\"                      \"elevationAccuracy\"             \n [87] \"samplingProtocol\"               \"recordNumber\"                  \n [89] \"nomenclaturalCode\"              \"samplingEffort\"                \n [91] \"county\"                         \"locality\"                      \n [93] \"verbatimCoordinateSystem\"       \"municipality\"                  \n [95] \"ownerInstitutionCode\"           \"verbatimElevation\"             \n [97] \"lifeStage\"                      \"sex\"                           \n [99] \"organismQuantity\"               \"organismQuantityType\"          \n[101] \"institutionKey\"                 \"collectionKey\"                 \n[103] \"preparations\"                   \"disposition\"                   \n[105] \"accessRights\"                   \"higherClassification\"          \n[107] \"collectionID\"                   \"name\"                          \n[109] \"otherCatalogNumbers\"            \"habitat\"                       \n[111] \"verbatimSRS\"                    \"verbatimTaxonRank\"             \n[113] \"eventID\"                        \"footprintWKT\"                  \n[115] \"georeferenceRemarks\"            \"parentEventID\"                 \n[117] \"networkKeys\"                    \"projectId\"                     \n[119] \"establishmentMeans\"             \"sampleSizeUnit\"                \n[121] \"eventRemarks\"                   \"fieldNumber\"                   \n[123] \"locationRemarks\"                \"fieldNotes\"                    \n[125] \"bibliographicCitation\"          \"verbatimIdentification\"        \n[127] \"sampleSizeValue\"                \"footprintSRS\"                  \n[129] \"waterBody\"                      \"locationID\"                    \n[131] \"georeferencedBy\"                \"georeferencedDate\"             \n[133] \"georeferenceProtocol\"           \"identificationRemarks\"         \n[135] \"georeferenceSources\"            \"organismID\"                    \n[137] \"higherGeography\"                \"georeferenceVerificationStatus\"\n[139] \"rights\"                         \"behavior\"                      \n[141] \"distanceFromCentroidInMeters\"   \"dynamicProperties\"             \n[143] \"locationAccordingTo\"            \"previousIdentifications\"       \n[145] \"identificationQualifier\"        \"coordinatePrecision\"           \n\nnrow(dat_sp1)\n\n[1] 2122\n\nncol(dat_sp1)\n\n[1] 146\n\nlength(unique(dat_sp1$stateProvince))\n\n[1] 22\n\nunique(dat_sp1$stateProvince)\n\n [1] \"Napo\"             \"Risaralda\"        \"Carchi\"           NA                \n [5] \"Huila\"            \"Loja\"             \"Zamora Chinchipe\" \"Imbabura\"        \n [9] \"Cauca\"            \"Tolima\"           \"Quindío\"          \"Sucumbios\"       \n[13] \"Valle del Cauca\"  \"Caldas\"           \"Tungurahua\"       \"Morona Santiago\" \n[17] \"Nariño\"           \"Sucumbíos\"        \"Pichincha\"        \"Narino\"          \n[21] \"Napo-Tungurahua\"  \"Antioquia\"       \n\nlength(unique(dat_sp1$year))\n\n[1] 26\n\nunique(dat_sp1$year)\n\n [1] 2024 2023 2022 2021 2020 2019 2018 2017 2016 2015 2014 2013 2011 2010 2009\n[16] 2008 2001 1993 1969 1968 1958 1957 1951 1936 1929   NA\n\ntable(dat_sp1$publishingCountry)\n\n\n  AU   CA   CH   CO   EC   MX   US \n   1    1    3  422 1575    2  118 \n\n# summary(dat)"
  },
  {
    "objectID": "AM.html#filtro-de-datos",
    "href": "AM.html#filtro-de-datos",
    "title": "AM",
    "section": "Filtro de datos",
    "text": "Filtro de datos\nEmpecemos por explorar los datos para una region. Para ello, podemos utilizar la función filter, filtrando los datos de Risaralda, Quindío, Caldas y Tolima.\n\ndat_nevados <- dplyr::filter(dat_sp1, stateProvince == c(\"Risaralda\", \"Quindío\", \"Caldas\", \"Tolima\")) \nhead(dat_nevados)\n\n# A tibble: 6 × 146\n  key        scientificName   decimalLatitude decimalLongitude issues datasetKey\n  <chr>      <chr>                      <dbl>            <dbl> <chr>  <chr>     \n1 4075998379 Tapirus pinchaq…            4.76            -75.4 cdc,c… 50c9509d-…\n2 4438769932 Tapirus pinchaq…            4.70            -75.4 cdc,c… 50c9509d-…\n3 4399886059 Tapirus pinchaq…            4.80            -75.6 cdc,c… 50c9509d-…\n4 4414236590 Tapirus pinchaq…            4.65            -75.5 cdc,c… 50c9509d-…\n5 3457155723 Tapirus pinchaq…            4.63            -75.6 cdc,c… 50c9509d-…\n6 3764161404 Tapirus pinchaq…            4.68            -75.5 cdc,c… 50c9509d-…\n# ℹ 140 more variables: publishingOrgKey <chr>, installationKey <chr>,\n#   hostingOrganizationKey <chr>, publishingCountry <chr>, protocol <chr>,\n#   lastCrawled <chr>, lastParsed <chr>, crawlId <int>, basisOfRecord <chr>,\n#   occurrenceStatus <chr>, taxonKey <int>, kingdomKey <int>, phylumKey <int>,\n#   classKey <int>, orderKey <int>, familyKey <int>, genusKey <int>,\n#   speciesKey <int>, acceptedTaxonKey <int>, acceptedScientificName <chr>,\n#   kingdom <chr>, phylum <chr>, order <chr>, family <chr>, genus <chr>, …\n\n\nTambién es posible que deseemos seleccionar algunas columnas de nuestro conjunto de datos. Podemos hacer esto fácilmente con las herramientas de indexación de dataframes de R. En nuestro caso selecionaremos las columnas que son de nuestro interes.\n\n# get the columns that matter for mapping and cleaning the occurrence data:\nsp1_coords <- gbif_data_sp1$data[ , c(\"scientificName\", \"decimalLongitude\", \"decimalLatitude\", \"individualCount\", \"occurrenceStatus\", \"coordinateUncertaintyInMeters\", \"institutionCode\", \"references\")]\nhead(sp1_coords)\n\n# A tibble: 6 × 8\n  scientificName                decimalLongitude decimalLatitude individualCount\n  <chr>                                    <dbl>           <dbl>           <int>\n1 Tapirus pinchaque (Roulin, 1…            -77.9          -0.525              NA\n2 Tapirus pinchaque (Roulin, 1…            -75.6           4.77               NA\n3 Tapirus pinchaque (Roulin, 1…            -77.9          -0.418              NA\n4 Tapirus pinchaque (Roulin, 1…            -77.9          -0.457              NA\n5 Tapirus pinchaque (Roulin, 1…            -77.9          -0.520              NA\n6 Tapirus pinchaque (Roulin, 1…            -77.9          -0.424              NA\n# ℹ 4 more variables: occurrenceStatus <chr>,\n#   coordinateUncertaintyInMeters <dbl>, institutionCode <chr>,\n#   references <chr>"
  },
  {
    "objectID": "AM.html#combinación-de-tablas",
    "href": "AM.html#combinación-de-tablas",
    "title": "AM",
    "section": "Combinación de tablas",
    "text": "Combinación de tablas\nNuestra tabla de registros tiene información específica sobre las localidades de una especie. Con el fin de entender como combinar tablas descargaremos los datos de otra especie. En este caso el Oso Andino (Tremarctos ornatus).\n\nspecies2 <- c(\"Tremarctos ornatus\")\n# download GBIF occurrence data for this species; this takes time if there are many data points!\ngbif_data_sp2 <- occ_data(scientificName = species2, hasCoordinate = TRUE, limit = 20000)\ndat_sp2 <- gbif_data_sp2$data\n\ndplyr proporciona un conjunto útil de funciones para unir tablas que tienen columnas en común. Escriba ?full_join en su consola y obtendrá una lista de todos los tipos de unión que admite dplyr.\nHoy usaremos full_join para unir los registros de dos especies en una sola tabla. La funcion full_join permite mantener las filas que no coinciden también). Otras funcionalidades de join se ven en la version ampliada de este curso.\n\ndat_oso_danta  <- full_join(x = dat_sp2, y = dat_sp1)"
  },
  {
    "objectID": "PM.html",
    "href": "PM.html",
    "title": "PM",
    "section": "",
    "text": "Comenzamos cargando tres paquetes básicos necesarios para generar nuestros primeros mapas; mapview, sf y ggplot2.\n\n\nCode\nlibrary(mapview)\nlibrary(ggplot2)\nlibrary(sf)\n\n\nTambién utilizaremos el paquete maps para cargar un mapa global. Existen otros paquetes que también funcionan para este propósito, como el paquete rnaturalearth, el cual proporciona un mapa de países de todo el mundo.\n\n\nCode\nlibrary(maps)\n\n\nAhora podemos cargar el mapa global usando la función map(). Además, transformaremos el objeto world a un simple feature o sf, este representa características simples como registros en un data.frame o tibble (tabla) con una lista-columna de geometrías (punto, linea, poligono, etc) que representan la forma, mas un sistema de coordendas.\n\n\nCode\nworld1 <- sf::st_as_sf(map(database = 'world', plot = FALSE, fill = TRUE))\nworld1\n\n\nSimple feature collection with 253 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -180 ymin: -85.19218 xmax: 190.2708 ymax: 83.59961\nGeodetic CRS:  +proj=longlat +ellps=clrk66 +no_defs +type=crs\nFirst 10 features:\n                                       ID                           geom\nAruba                               Aruba MULTIPOLYGON (((-69.89912 1...\nAfghanistan                   Afghanistan MULTIPOLYGON (((74.89131 37...\nAngola                             Angola MULTIPOLYGON (((23.9665 -10...\nAnguilla                         Anguilla MULTIPOLYGON (((-63.00122 1...\nAlbania                           Albania MULTIPOLYGON (((20.06396 42...\nFinland                           Finland MULTIPOLYGON (((20.61133 60...\nAndorra                           Andorra MULTIPOLYGON (((1.706055 42...\nUnited Arab Emirates United Arab Emirates MULTIPOLYGON (((53.92783 24...\nArgentina                       Argentina MULTIPOLYGON (((-64.54916 -...\nArmenia                           Armenia MULTIPOLYGON (((45.55235 40...\n\n\nEjercicio\nIdentifique las principales características del objeto world1:\n¿Cuántos atributos y polígonos tiene? ¿Cuál es el sistema de coordenadas? ¿Cuál es su extensión?\nEjecicio extra ¿Cómo reescribiría la función anterior utilizando %>% ?\nAhora veamos el objeto world1 usando la función plot\n\n\nCode\nplot(world1)\n\n\n\n\n\nAhora podemos generar un plot utilizando el paquete ggplot y los conceptos aprendidos durante el día anterior.\nEn este caso, debemos utilizar geom_sf() con el fin de llamar nuestro objeto sf\n\n\nCode\nggplot() +\n  geom_sf(data = world1) \n\n\n\n\n\nEl siguiente paso consiste en anadir puntos de distribución de especies sobre nuestro mapa. Para ello, vamos a utilizar los puntos de localidades descargados desde GBIF en la mañana.\n\n\nCode\nlibrary(tidyverse)\n\n\nPara añadir los puntos en nuestro mapa, utilizaremos la función geom_point()\n\n\n\n\n\nCode\nggplot() +\n  geom_sf(data = world1) +\n  geom_point(data = dat_oso_danta_filtrado, aes(x = decimalLongitude, y = decimalLatitude))\n\n\n\n\n\nNote que hemos utilizado ggplot() sin algún argumento dentro de los corchetes. Esto se debe a que trazamos varias capas, cada una con una fuente de datos diferente, por lo que debemos especificar los datos proporcionados a cada geom por separado (data = world1 para geom_sf() y data = dat para geom_point).\nEste mapa se ve bien, pero no es necesario que representemos al mundo entero aquí. Por lo tanto, podemos modificar nuestro mapa estableciendo límites en las coordenadas. Además, podemos cambiar los colores de nuestros objetos.\nEn primer lugar, necesitamos definir la extensión de nuestros puntos\n\n\nCode\nrange(dat_oso_danta_filtrado$decimalLongitude)\n\n\n[1] -79.8566 -65.9310\n\n\nCode\nrange(dat_oso_danta_filtrado$decimalLatitude)\n\n\n[1] -17.39878  10.67390\n\n\nEstos son los valores que utilizaremos de guía para definir la extensión de nuestro mapa mediante el uso de coord_sf(). Note que vamos a añadir o los argumentos xlim y ylim que definen el limite de nuestro mapa\nEl nuevo mapa con la extensión corregida luce de la siguiente manera:\n\n\nCode\nggplot() +\n  geom_sf(data = world1) +\n  geom_point(data = dat_oso_danta_filtrado, aes(x = decimalLongitude, y = decimalLatitude)) +\n  coord_sf(xlim = c(-79.8566, -65.9310), ylim =  c(-17.39878, 10.67390)) +\n  labs(y = \"latitude\", x = \"longitude\") +\n  theme_bw()\n\n\n\n\n\nEjercicio\nGenere el mismo mapa pero esta vez coloree los puntos de acuerdo a la especie. Además, cambie el color de los países a verde usando la siguiente opción:\ncolor = “black”, fill = “lightgreen”\n\n\n\n\n\nHasta aca hemos aprendido un vistazo general sobre las caracteristicas vectoriales (puntos, lineas, poligonos) de los mapas. Sin embargo gran parte de los mapas tienen otro tipo de informacion que no es vectorial.\n\n\n\nUn ráster es una estructura de datos espaciales (geográficos) que divide una región en rectángulos llamados “celdas” (o “píxeles”) que pueden almacenar uno o más valores para cada una de estas celdas. Esta estructura de datos también se conoce como “cuadrícula” (o grid) y a contrasta con los datos “vectoriales” que se utilizan para representar puntos, líneas y polígonos.\nLos objetos ráster, se pueden leer y manipular con el paquete terra. Carguemos ese paquete ahora:\n\n\nCode\nlibrary(terra)\n\n\nLa función terra() nos sirve para cargar y manipular objetos raster dentro de R.\nPara este ejercicio vamos a descargar un modelo digital de elevación de terreno (DEM) usando el paquete elevatr, el cual descarga la topografia desde Amazon Web Services (AWS). Como fuente podemos usar cualquier mapa sf, en nuestro caso usaremos el mapa de puntos de la danta y el oso el cual convertiremos a sf.\nEn este caso, cargaremos una capa de elevación para el territorio colombiano.\n\n\nCode\n# definir CRS\nprojlatlon <- \"+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\"\n# convertir tabla de puntos a sf\ndanta_oso_sf <- st_as_sf(x = dat_oso_danta_filtrado,\n                         coords = c(\"decimalLongitude\", \"decimalLatitude\"),\n                            crs = projlatlon)\n\nlibrary(elevatr)\nelevation <- get_elev_raster(danta_oso_sf, z=4) # z define el nivel de zoom \nterra::plot(elevation)\n\n\n\n\n\nTome un tiempo para inspeccionar las principales características del raster, incluyendo su resolución y extensión.\nLa función plot() del paquete raster crea una primera gráfica bastante decente. Sin embargo, tenga en cuenta que la escala de colores no es tan apropiada para las elevaciones: verde donde las elevaciones son altas y rojo donde son bajas. Además, estos colores predeterminados no serían tan buenos si nuestra audiencia no pudiese ver el color rojo-verde.\nVamos entonces a crear el gráfico anterior usando ggplot. Antes de esto, necesitamos convertir el ráster en una tabla:\n\n\nCode\ndat_grid <- \n  data.frame(xyFromCell(elevation, 1:ncell(elevation)),\n             vals = elevation[]) %>%\n  as_tibble()\nhead(dat_grid)\n\n\n# A tibble: 6 × 3\n      x     y  vals\n  <dbl> <dbl> <dbl>\n1 -90.0  21.9   -39\n2 -89.9  21.9   -38\n3 -89.9  21.9   -39\n4 -89.8  21.9   -39\n5 -89.8  21.9   -39\n6 -89.8  21.9   -39\n\n\nAhora podemos incluir el raster en nuestro mapa utilizando la función geom_tile()\n\n\nCode\nggplot() +\n  geom_tile(data = dat_grid, aes(x = x, y = y, fill = vals)) +\n  geom_sf(data = world1, color = \"black\", fill = NA) +\n  geom_sf(data = danta_oso_sf, aes(color = scientificName)) +\n  coord_sf(xlim = c(-80, -49), ylim =  c(-13.5, 13)) +\n  labs(y = \"latitude\", x = \"longitude\") +\n  theme_bw()\n\n\n\n\n\nPodemos mejorar el mapa anterior cambiando el azul por gris\n\n\nCode\nggplot() +\n  geom_tile(data = dat_grid, aes(x = x, y = y, fill = vals)) +\n  scale_fill_distiller(type = \"seq\", palette = \"Greys\",\n                        direction = 1) +\n  geom_sf(data = world1, color = \"black\", fill = NA) +\n  geom_sf(data = danta_oso_sf, aes(color = scientificName)) +\n  coord_sf(xlim = c(-80, -49), ylim =  c(-13.5, 13)) +\n  labs(y = \"latitude\", x = \"longitude\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nLa función terrain nos permite obtener mapas de la pendiente, el aspecto y la rugosidad los cuales usaremos mas adelante.\n\n\nCode\nterreno <- terrain(elevation, c( \"slope\", \"aspect\", \"roughness\"))\nterreno # nuevo objeto con varios raster\n\n\nclass      : RasterBrick \ndimensions : 1011, 1037, 1048407, 3  (nrow, ncol, ncell, nlayers)\nresolution : 0.04340482, 0.04340482  (x, y)\nextent     : -90, -44.9892, -21.93923, 21.94305  (xmin, xmax, ymin, ymax)\ncrs        : +proj=longlat +datum=WGS84 +no_defs \nsource     : memory\nnames      :    roughness,        slope,       aspect \nmin values :            0,            0,            0 \nmax values : 4453.0000000,    0.3837085,    6.2831853 \n\n\nCode\nplot (terreno)"
  },
  {
    "objectID": "PM.html#extraer-datos-de-un-raster-basados-en-un-sf",
    "href": "PM.html#extraer-datos-de-un-raster-basados-en-un-sf",
    "title": "PM",
    "section": "Extraer datos de un raster basados en un sf",
    "text": "Extraer datos de un raster basados en un sf\n\n\nCode\ncovariables<- terra::extract (terreno, danta_oso_sf)\nhead(covariables)\n\n\n     roughness      slope     aspect\n[1,]       307 0.01862192 0.01528054\n[2,]       413 0.02138133 4.85660231\n[3,]       472 0.03176053 1.06784213\n[4,]       476 0.03902415 5.74084536\n[5,]       884 0.07371204 6.06315362\n[6,]       890 0.06135130 2.03976466\n\n\nAhora adicionemos la informacion de la especie.\n\n\nCode\ndat_mamm<-cbind(covariables, danta_oso_sf$scientificName)\nsummary(dat_mamm)"
  },
  {
    "objectID": "PM.html#graficas-adicionales",
    "href": "PM.html#graficas-adicionales",
    "title": "PM",
    "section": "graficas adicionales",
    "text": "graficas adicionales\nEjercicio\nGenere un histograma mostrando la distribución de la pendiente y la rugosidad para los registros de cada especie."
  },
  {
    "objectID": "PM.html#obtenga-ayuda",
    "href": "PM.html#obtenga-ayuda",
    "title": "PM",
    "section": "Obtenga ayuda",
    "text": "Obtenga ayuda\nEscribir código consiste en ensayo error y un 90% buscar la respuesta en Google.\nSi busca un problema en la web, como “ggplot remove legend”, normalmente obtendrá una respuesta bastante decente en Stack Overflow o en un sitio similar.\nSi la respuesta aún no existe en línea, regístrese en Stack Overflow y pregúntela usted mismo (pero primer dedique tiempo suficiente en buscar … ¡nadie quiere ser etiquetado por duplicar una pregunta existente!).\nOtra buena idea es buscar un grupo de apoyo local. El uso de R es una experiencia emocional, la curva de aprendizaje al comienzo es bien empinada, la frustración es común, pero luego de un tiempo la alegría de encontrar una solución puede ayudarnos a persistir. Tener a otras personas para ayudar, o simplemente escuchar sus frustraciones es una gran motivación para seguir aprendiendo R.\n\n\n\ncoding"
  }
]